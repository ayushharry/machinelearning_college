{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LR.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayushharry/machinelearning_college/blob/master/LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkRJzpAZfUTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyLinearRegression:\n",
        "    def __init__(self, weight=3, bias=2, learning_rate=0.005,\n",
        "                 iterations=550):\n",
        "        self.weight = weight\n",
        "        self.bias = bias\n",
        "        self.learning_rate = learning_rate\n",
        "        self.iterations = iterations\n",
        "        self.cost_trend = []\n",
        "        self.cost = 0\n",
        "\n",
        "    def predict(self, xfeature):\n",
        "        predicted_set = []\n",
        "        for i in range(len(xfeature)):\n",
        "            predicted_value = self.weight * xfeature[i] + self.bias\n",
        "            predicted_set.append(predicted_value)\n",
        "        return predicted_set\n",
        "\n",
        "    def cost_function(self, xfeature, yfeature):\n",
        "        count = len(xfeature)\n",
        "        total_error = 0.0\n",
        "        for i in range(count):\n",
        "            total_error += (yfeature[i] - (self.weight * xfeature[i] +\n",
        "                            self.bias)) ** 2\n",
        "        return float(total_error) / (2 * count)\n",
        "\n",
        "    def update_weights(self, xfeature, yfeature):\n",
        "        weight_deriv = 0\n",
        "        bias_deriv = 0\n",
        "        count = len(xfeature)\n",
        "\n",
        "        for i in range(count):\n",
        "            # Calculate partial derivatives\n",
        "            # -2x(y - (mx + b))\n",
        "            weight_deriv += -2 * xfeature[i] * (yfeature[i] -\n",
        "                                                (self.weight * xfeature[i] +\n",
        "                                                 self.bias))\n",
        "\n",
        "            # -2(y - (mx + b))\n",
        "            bias_deriv += -2 * (yfeature[i] - (self.weight * xfeature[i] +\n",
        "                                self.bias))\n",
        "\n",
        "        # We subtract because the derivatives point in direction of steepest\n",
        "        # ascent\n",
        "        self.weight -= (weight_deriv / count) * self.learning_rate\n",
        "        self.bias -= (bias_deriv / count) * self.learning_rate\n",
        "\n",
        "    def train(self, xfeature, yfeature):\n",
        "        for i in range(self.iterations):\n",
        "            self.update_weights(xfeature, yfeature)\n",
        "            # Calculating cost\n",
        "            self.cost = self.cost_function(xfeature, yfeature)\n",
        "            self.cost_trend.append(self.cost)\n",
        "            print(\"Iteration: {}\\t Weight: {}\\t Bias: {}\\t Cost: {}\".\n",
        "                      format(i, self.weight, self.bias, self.cost))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZhPdTtHoEjN",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIhWZzM2fUTN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# intialise data of lists. \n",
        "data = {'Hours':[2.5,5.1,3.2,8.5,3.5,1.5,9.2,5.5,8.3,2.7,7.7,5.9,4.5,3.3,1.1,8.9,2.5,1.9,6.1,7.4,2.7,4.8,3.8,6.9,7.8], \n",
        "        'Scores':[21,47,27,75,30,20,88,60,81,25,85,62,41,42,17,95,30,24,67,69,30,54,35,76,86]} \n",
        "  \n",
        "# Create DataFrame \n",
        "studentscores = pd.DataFrame(data) \n",
        "  \n",
        "# Print the output. \n",
        "studentscores "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tB6qrJrPfUTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from my_linear_regression import MyLinearRegression\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Importing the dataset\n",
        "\n",
        "X = studentscores.iloc[:, :-1].values\n",
        "y = studentscores.iloc[:, 1].values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxSazDuOfUTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)\n",
        "\n",
        "# Fitting Simple Linear Regression to the Training set\n",
        "regressor = MyLinearRegression()\n",
        "regressor.train(X_train, y_train)\n",
        "print('Weight: ' + str(regressor.weight) + ' Bias: ' + str(regressor.bias))\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-Cb6LzTfUTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualising the Training set results\n",
        "plt.scatter(X_train, y_train, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train), color='blue')\n",
        "plt.title('Salary vs Experience (Training set)')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.plot(regressor.cost_trend, color='blue')\n",
        "plt.title('Cost Flow')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Cost')\n",
        "plt.show()\n",
        "\n",
        "# Visualising the Test set results\n",
        "plt.scatter(X_test, y_test, color='red')\n",
        "plt.plot(X_train, regressor.predict(X_train), color='blue')\n",
        "plt.title('Salary vs Experience (Test set)')\n",
        "plt.xlabel('Years of Experience')\n",
        "plt.ylabel('Salary')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIq43yKPfUTz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}